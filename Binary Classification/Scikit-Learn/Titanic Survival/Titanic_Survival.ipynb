{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival\n",
    "We will load a Dataset of Titanic passenger list and define if they survive or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMTunerCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Data-Science/Binary Classification/Scikit-Learn/Titanic Survival/train.csv')\n",
    "test_df = pd.read_csv('Data-Science/Binary Classification/Scikit-Learn/Titanic Survival/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Cabin'].fillna('0', inplace=True)\n",
    "test_df['Cabin'].fillna('0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age'].fillna(train_df['Age'].mean(), inplace=True)\n",
    "test_df['Age'].fillna(test_df['Age'].mean(), inplace=True)\n",
    "\n",
    "train_df['Embarked'].fillna('0', inplace=True)\n",
    "test_df['Embarked'].fillna('0', inplace=True)\n",
    "\n",
    "train_df['Fare'].fillna(train_df['Fare'].mean(), inplace=True)\n",
    "test_df['Fare'].fillna(test_df['Fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding string variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df['Sex_encoded'] = label_encoder.fit_transform(train_df['Sex'])\n",
    "train_df['Embarked_encoded'] = label_encoder.fit_transform(train_df['Embarked'])\n",
    "train_df['Cabin_encoded'] = label_encoder.fit_transform(train_df['Cabin'])\n",
    "test_df['Sex_encoded'] = label_encoder.fit_transform(test_df['Sex'])\n",
    "test_df['Embarked_encoded'] = label_encoder.fit_transform(test_df['Embarked'])\n",
    "test_df['Cabin_encoded'] = label_encoder.fit_transform(test_df['Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop variables and divide dataset in features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_df=train_df['Survived']\n",
    "features_df=train_df.loc[:, train_df.columns.isin(['Sex_encoded', 'Pclass', 'Age', 'SibSp', 'Parch'])]\n",
    "test_features_df=test_df.loc[:, test_df.columns.isin(['Sex_encoded', 'Pclass', 'Age', 'SibSp', 'Parch'])]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features_df = pd.DataFrame(scaler.fit_transform(features_df), columns=features_df.columns)\n",
    "test_features_df = pd.DataFrame(scaler.fit_transform(test_features_df), columns=test_features_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId         0\n",
      "Survived            0\n",
      "Pclass              0\n",
      "Name                0\n",
      "Sex                 0\n",
      "Age                 0\n",
      "SibSp               0\n",
      "Parch               0\n",
      "Ticket              0\n",
      "Fare                0\n",
      "Cabin               0\n",
      "Embarked            0\n",
      "Sex_encoded         0\n",
      "Embarked_encoded    0\n",
      "Cabin_encoded       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find NaN values in train_df\n",
    "nan_counts = train_df.isnull().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass         0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Sex_encoded    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = test_features_df.isnull().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>Cabin_encoded</th>\n",
       "      <th>xgb_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Sex_encoded  \\\n",
       "0  34.5      0      0   330911   7.8292     0        Q            1   \n",
       "1  47.0      1      0   363272   7.0000     0        S            0   \n",
       "2  62.0      0      0   240276   9.6875     0        Q            1   \n",
       "3  27.0      0      0   315154   8.6625     0        S            1   \n",
       "4  22.0      1      1  3101298  12.2875     0        S            0   \n",
       "\n",
       "   Embarked_encoded  Cabin_encoded  xgb_survived  \n",
       "0                 1              0             0  \n",
       "1                 2              0             0  \n",
       "2                 1              0             0  \n",
       "3                 2              0             0  \n",
       "4                 2              0             0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(features_df, labels_df)\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_clf = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "xgb_predictions = best_xgb_clf.predict(test_features_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add the predictions to the test dataframe\n",
    "test_df['xgb_survived'] = xgb_predictions\n",
    "\n",
    "# Display the first few rows of the test dataframe to verify the predictions\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "4  Sex_encoded    0.782069\n",
      "0       Pclass    0.119407\n",
      "2        SibSp    0.040237\n",
      "1          Age    0.031631\n",
      "3        Parch    0.026655\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances = best_xgb_clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': features_df.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 02:13:16,982] A new study created in memory with name: no-name-0246ca7b-cc0d-4e63-8a33-d4612f148b2b\n",
      "[I 2024-10-18 02:13:17,192] Trial 0 finished with value: 0.5776215044672071 and parameters: {'num_leaves': 31, 'max_depth': 4, 'learning_rate': 0.0017269497317709168, 'n_estimators': 147, 'subsample': 0.623845062913346, 'colsample_bytree': 0.9928278256087459, 'min_child_weight': 9}. Best is trial 0 with value: 0.5776215044672071.\n",
      "[I 2024-10-18 02:13:20,234] Trial 1 finished with value: 0.4090882922182388 and parameters: {'num_leaves': 123, 'max_depth': 8, 'learning_rate': 0.003309398116817937, 'n_estimators': 492, 'subsample': 0.9070848376721469, 'colsample_bytree': 0.9824295834511557, 'min_child_weight': 5}. Best is trial 1 with value: 0.4090882922182388.\n",
      "[I 2024-10-18 02:13:21,101] Trial 2 finished with value: 0.42936094682300086 and parameters: {'num_leaves': 54, 'max_depth': 6, 'learning_rate': 0.006077596848299224, 'n_estimators': 237, 'subsample': 0.9252414020554899, 'colsample_bytree': 0.8288483490144412, 'min_child_weight': 2}. Best is trial 1 with value: 0.4090882922182388.\n",
      "[I 2024-10-18 02:13:22,744] Trial 3 finished with value: 0.5411646212573347 and parameters: {'num_leaves': 100, 'max_depth': 5, 'learning_rate': 0.0019057942919631123, 'n_estimators': 303, 'subsample': 0.8455964124552159, 'colsample_bytree': 0.6958897276156553, 'min_child_weight': 7}. Best is trial 1 with value: 0.4090882922182388.\n",
      "[I 2024-10-18 02:13:27,081] Trial 4 finished with value: 0.4677984065917324 and parameters: {'num_leaves': 32, 'max_depth': 5, 'learning_rate': 0.001419809732528191, 'n_estimators': 711, 'subsample': 0.8736906269439206, 'colsample_bytree': 0.7384315508957598, 'min_child_weight': 10}. Best is trial 1 with value: 0.4090882922182388.\n",
      "[I 2024-10-18 02:13:27,467] Trial 5 finished with value: 0.3544430357727393 and parameters: {'num_leaves': 137, 'max_depth': 13, 'learning_rate': 0.0342547527665426, 'n_estimators': 201, 'subsample': 0.9093795792848919, 'colsample_bytree': 0.603184404337501, 'min_child_weight': 4}. Best is trial 5 with value: 0.3544430357727393.\n",
      "[I 2024-10-18 02:13:32,694] Trial 6 finished with value: 0.37221911081266995 and parameters: {'num_leaves': 118, 'max_depth': 5, 'learning_rate': 0.0041954467033997, 'n_estimators': 911, 'subsample': 0.8725436730119088, 'colsample_bytree': 0.8491961887454699, 'min_child_weight': 5}. Best is trial 5 with value: 0.3544430357727393.\n",
      "[I 2024-10-18 02:13:33,566] Trial 7 finished with value: 0.49911618313174727 and parameters: {'num_leaves': 66, 'max_depth': 4, 'learning_rate': 0.0013893737015719424, 'n_estimators': 473, 'subsample': 0.617303892282297, 'colsample_bytree': 0.9009693303911078, 'min_child_weight': 6}. Best is trial 5 with value: 0.3544430357727393.\n",
      "[I 2024-10-18 02:13:35,102] Trial 8 finished with value: 0.24907882151362026 and parameters: {'num_leaves': 48, 'max_depth': 14, 'learning_rate': 0.09393230084073322, 'n_estimators': 698, 'subsample': 0.9861011694430519, 'colsample_bytree': 0.6706732592172152, 'min_child_weight': 10}. Best is trial 8 with value: 0.24907882151362026.\n",
      "[I 2024-10-18 02:13:36,788] Trial 9 finished with value: 0.4752993991634234 and parameters: {'num_leaves': 99, 'max_depth': 15, 'learning_rate': 0.001903102699478274, 'n_estimators': 591, 'subsample': 0.862165808614682, 'colsample_bytree': 0.6823085072853571, 'min_child_weight': 7}. Best is trial 8 with value: 0.24907882151362026.\n",
      "[I 2024-10-18 02:13:38,992] Trial 10 finished with value: 0.2362764615783829 and parameters: {'num_leaves': 66, 'max_depth': 12, 'learning_rate': 0.0981228712070061, 'n_estimators': 926, 'subsample': 0.9826508072136476, 'colsample_bytree': 0.6192457863671563, 'min_child_weight': 1}. Best is trial 10 with value: 0.2362764615783829.\n",
      "[I 2024-10-18 02:13:42,247] Trial 11 finished with value: 0.2371421017558887 and parameters: {'num_leaves': 66, 'max_depth': 12, 'learning_rate': 0.09141364889888648, 'n_estimators': 982, 'subsample': 0.9938584590274835, 'colsample_bytree': 0.6002519021251614, 'min_child_weight': 1}. Best is trial 10 with value: 0.2362764615783829.\n",
      "[I 2024-10-18 02:13:44,936] Trial 12 finished with value: 0.2358158902670644 and parameters: {'num_leaves': 76, 'max_depth': 11, 'learning_rate': 0.09986979672779048, 'n_estimators': 956, 'subsample': 0.996303682710183, 'colsample_bytree': 0.6071804944129395, 'min_child_weight': 1}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:13:47,142] Trial 13 finished with value: 0.27810947577193407 and parameters: {'num_leaves': 82, 'max_depth': 11, 'learning_rate': 0.026142485904896175, 'n_estimators': 856, 'subsample': 0.7737990674005444, 'colsample_bytree': 0.7599240971618737, 'min_child_weight': 3}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:13:49,425] Trial 14 finished with value: 0.2787605613180853 and parameters: {'num_leaves': 84, 'max_depth': 10, 'learning_rate': 0.039691991592720445, 'n_estimators': 813, 'subsample': 0.7563176640430067, 'colsample_bytree': 0.6454396271424112, 'min_child_weight': 1}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:13:51,410] Trial 15 finished with value: 0.32748556520362465 and parameters: {'num_leaves': 63, 'max_depth': 8, 'learning_rate': 0.016020814132256766, 'n_estimators': 753, 'subsample': 0.9578604076195103, 'colsample_bytree': 0.7464432983222935, 'min_child_weight': 3}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:13:54,233] Trial 16 finished with value: 0.25191597929250187 and parameters: {'num_leaves': 98, 'max_depth': 10, 'learning_rate': 0.06484724373284073, 'n_estimators': 994, 'subsample': 0.7190668635283431, 'colsample_bytree': 0.6407397494765713, 'min_child_weight': 2}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:13:55,727] Trial 17 finished with value: 0.3380579457566359 and parameters: {'num_leaves': 45, 'max_depth': 12, 'learning_rate': 0.012692615169637286, 'n_estimators': 610, 'subsample': 0.9499668314268453, 'colsample_bytree': 0.7106278313128229, 'min_child_weight': 1}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:13:57,897] Trial 18 finished with value: 0.26705735762594107 and parameters: {'num_leaves': 78, 'max_depth': 9, 'learning_rate': 0.05226878405139838, 'n_estimators': 893, 'subsample': 0.8193386109018319, 'colsample_bytree': 0.6279553484940967, 'min_child_weight': 3}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:14:00,981] Trial 19 finished with value: 0.33101968512067703 and parameters: {'num_leaves': 113, 'max_depth': 15, 'learning_rate': 0.02134554781504724, 'n_estimators': 432, 'subsample': 0.6953192118034197, 'colsample_bytree': 0.7715890125751794, 'min_child_weight': 2}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:14:03,376] Trial 20 finished with value: 0.3531015521379746 and parameters: {'num_leaves': 24, 'max_depth': 13, 'learning_rate': 0.008741797726860259, 'n_estimators': 804, 'subsample': 0.9898215633488356, 'colsample_bytree': 0.9013329385091544, 'min_child_weight': 4}. Best is trial 12 with value: 0.2358158902670644.\n",
      "[I 2024-10-18 02:14:08,586] Trial 21 finished with value: 0.23564592689288366 and parameters: {'num_leaves': 69, 'max_depth': 12, 'learning_rate': 0.09223318246766946, 'n_estimators': 991, 'subsample': 0.9938493686871572, 'colsample_bytree': 0.602677355455781, 'min_child_weight': 1}. Best is trial 21 with value: 0.23564592689288366.\n",
      "[I 2024-10-18 02:14:10,811] Trial 22 finished with value: 0.2545144140779298 and parameters: {'num_leaves': 73, 'max_depth': 11, 'learning_rate': 0.06312091798735334, 'n_estimators': 922, 'subsample': 0.9558734453921157, 'colsample_bytree': 0.652728719814122, 'min_child_weight': 1}. Best is trial 21 with value: 0.23564592689288366.\n",
      "[I 2024-10-18 02:14:14,014] Trial 23 finished with value: 0.23496867374931762 and parameters: {'num_leaves': 92, 'max_depth': 13, 'learning_rate': 0.09483189843565419, 'n_estimators': 999, 'subsample': 0.935571331087194, 'colsample_bytree': 0.6044434777338638, 'min_child_weight': 2}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:17,154] Trial 24 finished with value: 0.2638854825823786 and parameters: {'num_leaves': 97, 'max_depth': 13, 'learning_rate': 0.0453528968037046, 'n_estimators': 978, 'subsample': 0.9334844459573556, 'colsample_bytree': 0.6754422984221202, 'min_child_weight': 2}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:23,144] Trial 25 finished with value: 0.23766151628642596 and parameters: {'num_leaves': 93, 'max_depth': 14, 'learning_rate': 0.06692059723915056, 'n_estimators': 814, 'subsample': 0.898900762373196, 'colsample_bytree': 0.719965533459755, 'min_child_weight': 3}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:29,783] Trial 26 finished with value: 0.28517382659776974 and parameters: {'num_leaves': 108, 'max_depth': 11, 'learning_rate': 0.026861762275097727, 'n_estimators': 994, 'subsample': 0.9996985130820768, 'colsample_bytree': 0.6342713074846273, 'min_child_weight': 4}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:32,295] Trial 27 finished with value: 0.26574009570696916 and parameters: {'num_leaves': 144, 'max_depth': 9, 'learning_rate': 0.07281781003162242, 'n_estimators': 674, 'subsample': 0.9562638736137401, 'colsample_bytree': 0.6603748837997028, 'min_child_weight': 2}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:35,488] Trial 28 finished with value: 0.2623567657872521 and parameters: {'num_leaves': 89, 'max_depth': 14, 'learning_rate': 0.0360120120852705, 'n_estimators': 857, 'subsample': 0.8314159866376413, 'colsample_bytree': 0.7900346682314345, 'min_child_weight': 1}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:37,817] Trial 29 finished with value: 0.2636359711917013 and parameters: {'num_leaves': 40, 'max_depth': 10, 'learning_rate': 0.05144232195959869, 'n_estimators': 931, 'subsample': 0.6633155821643207, 'colsample_bytree': 0.6023648899948872, 'min_child_weight': 2}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:39,531] Trial 30 finished with value: 0.24275264070243055 and parameters: {'num_leaves': 75, 'max_depth': 7, 'learning_rate': 0.09886763273826377, 'n_estimators': 764, 'subsample': 0.9643756921944783, 'colsample_bytree': 0.7092247602050797, 'min_child_weight': 7}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:41,871] Trial 31 finished with value: 0.2359704320996172 and parameters: {'num_leaves': 56, 'max_depth': 12, 'learning_rate': 0.09913023837723385, 'n_estimators': 932, 'subsample': 0.974930848576041, 'colsample_bytree': 0.6243556917256897, 'min_child_weight': 1}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:44,172] Trial 32 finished with value: 0.2590356543869989 and parameters: {'num_leaves': 56, 'max_depth': 12, 'learning_rate': 0.058957210372081466, 'n_estimators': 863, 'subsample': 0.9307670051427162, 'colsample_bytree': 0.6205240771036159, 'min_child_weight': 1}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:46,441] Trial 33 finished with value: 0.2465554106124138 and parameters: {'num_leaves': 56, 'max_depth': 11, 'learning_rate': 0.0773603708648713, 'n_estimators': 926, 'subsample': 0.8979287034997645, 'colsample_bytree': 0.6546158465650531, 'min_child_weight': 2}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:47,246] Trial 34 finished with value: 0.2857041051432432 and parameters: {'num_leaves': 72, 'max_depth': 13, 'learning_rate': 0.07490896548423458, 'n_estimators': 343, 'subsample': 0.9719190776559032, 'colsample_bytree': 0.6183500696365801, 'min_child_weight': 3}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:49,510] Trial 35 finished with value: 0.26834481899014817 and parameters: {'num_leaves': 87, 'max_depth': 10, 'learning_rate': 0.04420478364204993, 'n_estimators': 958, 'subsample': 0.9273750733065226, 'colsample_bytree': 0.6890184163372758, 'min_child_weight': 8}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:54,132] Trial 36 finished with value: 0.26468844634202265 and parameters: {'num_leaves': 33, 'max_depth': 12, 'learning_rate': 0.02799510067575384, 'n_estimators': 883, 'subsample': 0.9078978679854129, 'colsample_bytree': 0.9466596880955566, 'min_child_weight': 2}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:14:57,840] Trial 37 finished with value: 0.35757643655296406 and parameters: {'num_leaves': 130, 'max_depth': 14, 'learning_rate': 0.005691283715560694, 'n_estimators': 756, 'subsample': 0.9422748807134393, 'colsample_bytree': 0.832318192186178, 'min_child_weight': 1}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:15:00,430] Trial 38 finished with value: 0.30526160906384353 and parameters: {'num_leaves': 57, 'max_depth': 13, 'learning_rate': 0.019164880323058044, 'n_estimators': 832, 'subsample': 0.9731898181643068, 'colsample_bytree': 0.6010848142914009, 'min_child_weight': 4}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:15:00,867] Trial 39 finished with value: 0.33681451599650275 and parameters: {'num_leaves': 47, 'max_depth': 11, 'learning_rate': 0.08216805272134532, 'n_estimators': 136, 'subsample': 0.8879725644878024, 'colsample_bytree': 0.6339767741297506, 'min_child_weight': 1}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:15:02,078] Trial 40 finished with value: 0.35168447006893344 and parameters: {'num_leaves': 106, 'max_depth': 3, 'learning_rate': 0.055872117456153225, 'n_estimators': 949, 'subsample': 0.9183729676781456, 'colsample_bytree': 0.6670587012862683, 'min_child_weight': 5}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:15:04,764] Trial 41 finished with value: 0.2400626809563063 and parameters: {'num_leaves': 64, 'max_depth': 12, 'learning_rate': 0.09311384195308363, 'n_estimators': 898, 'subsample': 0.9984648902916675, 'colsample_bytree': 0.6205435713302385, 'min_child_weight': 1}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:15:07,132] Trial 42 finished with value: 0.48825090811945 and parameters: {'num_leaves': 80, 'max_depth': 13, 'learning_rate': 0.00105260083289967, 'n_estimators': 944, 'subsample': 0.9789477704382057, 'colsample_bytree': 0.6187633900438805, 'min_child_weight': 1}. Best is trial 23 with value: 0.23496867374931762.\n",
      "[I 2024-10-18 02:15:09,946] Trial 43 finished with value: 0.23364389776392258 and parameters: {'num_leaves': 69, 'max_depth': 12, 'learning_rate': 0.09907275409643403, 'n_estimators': 988, 'subsample': 0.9763276293889558, 'colsample_bytree': 0.6472748222117203, 'min_child_weight': 2}. Best is trial 43 with value: 0.23364389776392258.\n",
      "[I 2024-10-18 02:15:12,457] Trial 44 finished with value: 0.24349865130723503 and parameters: {'num_leaves': 70, 'max_depth': 15, 'learning_rate': 0.07617339294557836, 'n_estimators': 993, 'subsample': 0.9426378569113463, 'colsample_bytree': 0.6940071315195517, 'min_child_weight': 2}. Best is trial 43 with value: 0.23364389776392258.\n",
      "[I 2024-10-18 02:15:15,607] Trial 45 finished with value: 0.23785486832057023 and parameters: {'num_leaves': 61, 'max_depth': 12, 'learning_rate': 0.09841213433507426, 'n_estimators': 890, 'subsample': 0.9724620406473745, 'colsample_bytree': 0.6450743274757939, 'min_child_weight': 3}. Best is trial 43 with value: 0.23364389776392258.\n",
      "[I 2024-10-18 02:15:18,797] Trial 46 finished with value: 0.4056770928030604 and parameters: {'num_leaves': 86, 'max_depth': 11, 'learning_rate': 0.0023911293950911704, 'n_estimators': 960, 'subsample': 0.8742884268401638, 'colsample_bytree': 0.6007838254565987, 'min_child_weight': 2}. Best is trial 43 with value: 0.23364389776392258.\n",
      "[I 2024-10-18 02:15:19,471] Trial 47 finished with value: 0.33305425817719014 and parameters: {'num_leaves': 52, 'max_depth': 14, 'learning_rate': 0.03344598178161088, 'n_estimators': 229, 'subsample': 0.9873677651193499, 'colsample_bytree': 0.6735280459738296, 'min_child_weight': 6}. Best is trial 43 with value: 0.23364389776392258.\n",
      "[I 2024-10-18 02:15:20,754] Trial 48 finished with value: 0.29780790922092 and parameters: {'num_leaves': 41, 'max_depth': 8, 'learning_rate': 0.04683288882080579, 'n_estimators': 513, 'subsample': 0.962676233550129, 'colsample_bytree': 0.6385099542705677, 'min_child_weight': 3}. Best is trial 43 with value: 0.23364389776392258.\n",
      "[I 2024-10-18 02:15:23,172] Trial 49 finished with value: 0.24452950612877947 and parameters: {'num_leaves': 92, 'max_depth': 10, 'learning_rate': 0.06367501648128472, 'n_estimators': 779, 'subsample': 0.8494340253841214, 'colsample_bytree': 0.8828102614779525, 'min_child_weight': 2}. Best is trial 43 with value: 0.23364389776392258.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>Cabin_encoded</th>\n",
       "      <th>xgb_survived</th>\n",
       "      <th>lgb_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Sex_encoded  \\\n",
       "0  34.5      0      0   330911   7.8292     0        Q            1   \n",
       "1  47.0      1      0   363272   7.0000     0        S            0   \n",
       "2  62.0      0      0   240276   9.6875     0        Q            1   \n",
       "3  27.0      0      0   315154   8.6625     0        S            1   \n",
       "4  22.0      1      1  3101298  12.2875     0        S            0   \n",
       "\n",
       "   Embarked_encoded  Cabin_encoded  xgb_survived  lgb_survived  \n",
       "0                 1              0             0             0  \n",
       "1                 2              0             0             0  \n",
       "2                 1              0             0             0  \n",
       "3                 2              0             0             0  \n",
       "4                 2              0             0             1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the dataset for LightGBM\n",
    "train_data = lgb.Dataset(features_df, labels_df)\n",
    "\n",
    "# Define the parameter search space\n",
    "param_grid = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Define the tuning function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    \n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        nfold=3,\n",
    "        stratified=True,\n",
    "        shuffle=True,\n",
    "        metrics='binary_logloss',\n",
    "        seed=42,\n",
    "        eval_train_metric=True,\n",
    "    )\n",
    "    return min(cv_results['train binary_logloss-mean'])\n",
    "\n",
    "# Create the study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_params.update(param_grid)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "lgb_clf = lgb.LGBMClassifier(**best_params)\n",
    "lgb_clf.fit(features_df, labels_df)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "lgb_predictions = lgb_clf.predict(test_features_df)\n",
    "\n",
    "# Add the predictions to the test dataframe\n",
    "test_df['lgb_survived'] = lgb_predictions\n",
    "\n",
    "# Display the first few rows of the test dataframe to verify the predictions\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>Cabin_encoded</th>\n",
       "      <th>xgb_survived</th>\n",
       "      <th>lgb_survived</th>\n",
       "      <th>log_reg_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Sex_encoded  \\\n",
       "0  34.5      0      0   330911   7.8292     0        Q            1   \n",
       "1  47.0      1      0   363272   7.0000     0        S            0   \n",
       "2  62.0      0      0   240276   9.6875     0        Q            1   \n",
       "3  27.0      0      0   315154   8.6625     0        S            1   \n",
       "4  22.0      1      1  3101298  12.2875     0        S            0   \n",
       "\n",
       "   Embarked_encoded  Cabin_encoded  xgb_survived  lgb_survived  \\\n",
       "0                 1              0             0             0   \n",
       "1                 2              0             0             0   \n",
       "2                 1              0             0             0   \n",
       "3                 2              0             0             0   \n",
       "4                 2              0             0             1   \n",
       "\n",
       "   log_reg_survived  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [100, 200, 300, 500, 1000]\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search_log_reg = RandomizedSearchCV(estimator=log_reg, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search_log_reg.fit(features_df, labels_df)\n",
    "\n",
    "# Get the best estimator\n",
    "best_log_reg = random_search_log_reg.best_estimator_\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "log_reg_predictions = best_log_reg.predict(test_features_df)\n",
    "\n",
    "# Add the predictions to the test dataframe\n",
    "test_df['log_reg_survived'] = log_reg_predictions\n",
    "\n",
    "# Display the first few rows of the test dataframe to verify the predictions\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>Cabin_encoded</th>\n",
       "      <th>xgb_survived</th>\n",
       "      <th>lgb_survived</th>\n",
       "      <th>log_reg_survived</th>\n",
       "      <th>dt_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Sex_encoded  \\\n",
       "0  34.5      0      0   330911   7.8292     0        Q            1   \n",
       "1  47.0      1      0   363272   7.0000     0        S            0   \n",
       "2  62.0      0      0   240276   9.6875     0        Q            1   \n",
       "3  27.0      0      0   315154   8.6625     0        S            1   \n",
       "4  22.0      1      1  3101298  12.2875     0        S            0   \n",
       "\n",
       "   Embarked_encoded  Cabin_encoded  xgb_survived  lgb_survived  \\\n",
       "0                 1              0             0             0   \n",
       "1                 2              0             0             0   \n",
       "2                 1              0             0             0   \n",
       "3                 2              0             0             0   \n",
       "4                 2              0             0             1   \n",
       "\n",
       "   log_reg_survived  dt_survived  \n",
       "0                 0            0  \n",
       "1                 0            1  \n",
       "2                 0            0  \n",
       "3                 0            0  \n",
       "4                 1            0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search_dt = RandomizedSearchCV(estimator=dt_clf, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search_dt.fit(features_df, labels_df)\n",
    "\n",
    "# Get the best estimator\n",
    "best_dt_clf = random_search_dt.best_estimator_\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "dt_predictions = best_dt_clf.predict(test_features_df)\n",
    "\n",
    "# Add the predictions to the test dataframe\n",
    "test_df['dt_survived'] = dt_predictions\n",
    "\n",
    "# Display the first few rows of the test dataframe to verify the predictions\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['PassengerId', 'xgb_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival/XGB_predictions.csv', index=False)\n",
    "test_df[['PassengerId', 'lgb_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival//LGB_predictions.csv', index=False)\n",
    "test_df[['PassengerId', 'log_reg_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival/LogReg_predictions.csv', index=False)\n",
    "test_df[['PassengerId', 'dt_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival/DT_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>Cabin_encoded</th>\n",
       "      <th>xgb_survived</th>\n",
       "      <th>lgb_survived</th>\n",
       "      <th>log_reg_survived</th>\n",
       "      <th>dt_survived</th>\n",
       "      <th>pooled_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Sex_encoded  \\\n",
       "0  34.5      0      0   330911   7.8292     0        Q            1   \n",
       "1  47.0      1      0   363272   7.0000     0        S            0   \n",
       "2  62.0      0      0   240276   9.6875     0        Q            1   \n",
       "3  27.0      0      0   315154   8.6625     0        S            1   \n",
       "4  22.0      1      1  3101298  12.2875     0        S            0   \n",
       "\n",
       "   Embarked_encoded  Cabin_encoded  xgb_survived  lgb_survived  \\\n",
       "0                 1              0             0             0   \n",
       "1                 2              0             0             0   \n",
       "2                 1              0             0             0   \n",
       "3                 2              0             0             0   \n",
       "4                 2              0             0             1   \n",
       "\n",
       "   log_reg_survived  dt_survived  pooled_survived  \n",
       "0                 0            0                0  \n",
       "1                 0            1                0  \n",
       "2                 0            0                0  \n",
       "3                 0            0                0  \n",
       "4                 1            0                0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pool of all predicted loan statuses\n",
    "test_df['pooled_survived'] = test_df[['xgb_survived', 'lgb_survived', 'log_reg_survived', 'dt_survived']].mode(axis=1)[0]\n",
    "test_df['pooled_survived'] = test_df['pooled_survived'].astype(int)\n",
    "# Display the first few rows of the test dataframe to verify the pooled predictions\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['PassengerId', 'pooled_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival/Pooled_Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'any_predicted_loan_status' where the value is 1 if any of the predictions is 1\n",
    "test_df['any_survived'] = test_df[['xgb_survived', 'lgb_survived', 'log_reg_survived', 'dt_survived']].max(axis=1)\n",
    "# Display the first few rows of the test dataframe to verify the new column\n",
    "test_df.head()\n",
    "test_df[['PassengerId', 'any_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival/Max_Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_decision_forests\n",
      "  Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.2.3)\n",
      "Requirement already satisfied: tensorflow==2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.17.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.1.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from tensorflow_decision_forests) (0.37.1)\n",
      "Collecting wurlitzer (from tensorflow_decision_forests)\n",
      "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tf-keras~=2.17 (from tensorflow_decision_forests)\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting ydf (from tensorflow_decision_forests)\n",
      "  Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (59.6.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0->tensorflow_decision_forests) (0.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->tensorflow_decision_forests) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.2)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (13.9.2)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0->tensorflow_decision_forests) (2020.6.20)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0->tensorflow_decision_forests) (3.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0->tensorflow_decision_forests) (0.1.2)\n",
      "Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
      "Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: ydf, wurlitzer, tf-keras, tensorflow_decision_forests\n",
      "Successfully installed tensorflow_decision_forests-1.10.0 tf-keras-2.17.0 wurlitzer-3.1.1 ydf-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow Decision Forests\n",
    "!pip install tensorflow_decision_forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp_t64otzr as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729228885.551084 1194904 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729228885.551142 1194904 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729228885.551153 1194904 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729228885.551216 1194904 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729228885.551220 1194904 kernel.cc:395] Number of examples: 891\n",
      "I0000 00:00:1729228885.551256 1194904 kernel.cc:794] Training dataset:\n",
      "Number of records: 891\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 5 (83.3333%)\n",
      "\tCATEGORICAL: 1 (16.6667%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 5 (83.3333%)\n",
      "\t0: \"Age\" NUMERICAL mean:29.6991 min:0.42 max:80 sd:12.9947\n",
      "\t1: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n",
      "\t2: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n",
      "\t3: \"Sex_encoded\" NUMERICAL mean:0.647587 min:0 max:1 sd:0.477722\n",
      "\t4: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n",
      "\n",
      "CATEGORICAL: 1 (16.6667%)\n",
      "\t5: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729228885.551271 1194904 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729228885.551386 1194904 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Parch$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^Sex_encoded$\"\n",
      "features: \"^SibSp$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729228885.551479 1194904 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/tmp/tmp_t64otzr/working_cache\"\n",
      "num_threads: 20\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729228885.551589 1195609 kernel.cc:888] Train model\n",
      "I0000 00:00:1729228885.551648 1195609 random_forest.cc:428] Training random forest on 891 example(s) and 5 feature(s).\n",
      "I0000 00:00:1729228885.554617 1195617 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.790274 logloss:7.55931\n",
      "I0000 00:00:1729228885.555699 1195621 random_forest.cc:812] Training of tree  13/300 (tree index:13) done accuracy:0.810069 logloss:4.30788\n",
      "I0000 00:00:1729228885.556848 1195619 random_forest.cc:812] Training of tree  23/300 (tree index:29) done accuracy:0.823793 logloss:3.03606\n",
      "I0000 00:00:1729228885.558947 1195623 random_forest.cc:812] Training of tree  33/300 (tree index:39) done accuracy:0.824916 logloss:2.84734\n",
      "I0000 00:00:1729228885.561002 1195634 random_forest.cc:812] Training of tree  43/300 (tree index:49) done accuracy:0.828283 logloss:2.69771\n",
      "I0000 00:00:1729228885.562403 1195632 random_forest.cc:812] Training of tree  53/300 (tree index:34) done accuracy:0.826038 logloss:2.54853\n",
      "I0000 00:00:1729228885.564877 1195624 random_forest.cc:812] Training of tree  64/300 (tree index:35) done accuracy:0.829405 logloss:2.47471\n",
      "I0000 00:00:1729228885.567436 1195624 random_forest.cc:812] Training of tree  74/300 (tree index:82) done accuracy:0.82716 logloss:2.36588\n",
      "I0000 00:00:1729228885.569944 1195631 random_forest.cc:812] Training of tree  84/300 (tree index:67) done accuracy:0.82716 logloss:2.32788\n",
      "I0000 00:00:1729228885.572875 1195617 random_forest.cc:812] Training of tree  94/300 (tree index:97) done accuracy:0.829405 logloss:2.18025\n",
      "I0000 00:00:1729228885.575655 1195615 random_forest.cc:812] Training of tree  104/300 (tree index:108) done accuracy:0.830527 logloss:2.1445\n",
      "I0000 00:00:1729228885.578878 1195619 random_forest.cc:812] Training of tree  114/300 (tree index:104) done accuracy:0.83165 logloss:2.10892\n",
      "I0000 00:00:1729228885.581180 1195615 random_forest.cc:812] Training of tree  124/300 (tree index:123) done accuracy:0.830527 logloss:2.07283\n",
      "I0000 00:00:1729228885.583843 1195623 random_forest.cc:812] Training of tree  134/300 (tree index:128) done accuracy:0.832772 logloss:2.07288\n",
      "I0000 00:00:1729228885.586501 1195617 random_forest.cc:812] Training of tree  144/300 (tree index:137) done accuracy:0.829405 logloss:2.00246\n",
      "I0000 00:00:1729228885.589305 1195627 random_forest.cc:812] Training of tree  154/300 (tree index:134) done accuracy:0.828283 logloss:2.00393\n",
      "I0000 00:00:1729228885.591904 1195615 random_forest.cc:812] Training of tree  164/300 (tree index:154) done accuracy:0.829405 logloss:2.00596\n",
      "I0000 00:00:1729228885.593966 1195622 random_forest.cc:812] Training of tree  174/300 (tree index:164) done accuracy:0.828283 logloss:2.00487\n",
      "I0000 00:00:1729228885.597092 1195627 random_forest.cc:812] Training of tree  184/300 (tree index:187) done accuracy:0.829405 logloss:2.00601\n",
      "I0000 00:00:1729228885.599204 1195630 random_forest.cc:812] Training of tree  194/300 (tree index:185) done accuracy:0.82716 logloss:1.93494\n",
      "I0000 00:00:1729228885.601250 1195622 random_forest.cc:812] Training of tree  204/300 (tree index:206) done accuracy:0.824916 logloss:1.89767\n",
      "I0000 00:00:1729228885.604200 1195620 random_forest.cc:812] Training of tree  214/300 (tree index:202) done accuracy:0.828283 logloss:1.86137\n",
      "I0000 00:00:1729228885.606664 1195615 random_forest.cc:812] Training of tree  224/300 (tree index:226) done accuracy:0.829405 logloss:1.86082\n",
      "I0000 00:00:1729228885.608460 1195623 random_forest.cc:812] Training of tree  234/300 (tree index:225) done accuracy:0.832772 logloss:1.85987\n",
      "I0000 00:00:1729228885.611673 1195629 random_forest.cc:812] Training of tree  244/300 (tree index:247) done accuracy:0.832772 logloss:1.82482\n",
      "I0000 00:00:1729228885.613770 1195625 random_forest.cc:812] Training of tree  254/300 (tree index:256) done accuracy:0.830527 logloss:1.75344\n",
      "I0000 00:00:1729228885.617337 1195624 random_forest.cc:812] Training of tree  264/300 (tree index:260) done accuracy:0.830527 logloss:1.75383\n",
      "I0000 00:00:1729228885.619632 1195624 random_forest.cc:812] Training of tree  274/300 (tree index:283) done accuracy:0.832772 logloss:1.7538\n",
      "I0000 00:00:1729228885.621426 1195634 random_forest.cc:812] Training of tree  284/300 (tree index:291) done accuracy:0.833894 logloss:1.71808\n",
      "I0000 00:00:1729228885.623927 1195620 random_forest.cc:812] Training of tree  294/300 (tree index:286) done accuracy:0.83165 logloss:1.64914\n",
      "I0000 00:00:1729228885.625113 1195625 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.83165 logloss:1.64907\n",
      "I0000 00:00:1729228885.625299 1195609 random_forest.cc:892] Final OOB metrics: accuracy:0.83165 logloss:1.64907\n",
      "I0000 00:00:1729228885.637268 1195609 kernel.cc:920] Export model in log directory: /tmp/tmp_t64otzr with prefix 4a723d25f63f49d8\n",
      "I0000 00:00:1729228885.662365 1195609 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729228885.665846 1194904 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 891\n",
      "Number of predictions (with weights): 891\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.83165  CI95[W][0.809661 0.851995]\n",
      "LogLoss: : 1.64907\n",
      "ErrorRate: : 0.16835\n",
      "\n",
      "Default Accuracy: : 0.616162\n",
      "Default LogLoss: : 0.665912\n",
      "Default ErrorRate: : 0.383838\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "     1    2\n",
      "1  497   52\n",
      "2   98  244\n",
      "Total: 891\n",
      "\n",
      "\n",
      "2024-10-18 02:21:25.678871: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /tmp/tmp_t64otzr/model/ with prefix 4a723d25f63f49d8\n",
      "I0000 00:00:1729228885.713219 1194904 decision_forest.cc:761] Model loaded with 300 root(s), 42076 node(s), and 5 input feature(s).\n",
      "I0000 00:00:1729228885.713278 1194904 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-18 02:21:25.713294: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>...</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>Cabin_encoded</th>\n",
       "      <th>xgb_survived</th>\n",
       "      <th>lgb_survived</th>\n",
       "      <th>log_reg_survived</th>\n",
       "      <th>dt_survived</th>\n",
       "      <th>pooled_survived</th>\n",
       "      <th>any_survived</th>\n",
       "      <th>tfdf_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin  ... Sex_encoded  \\\n",
       "0  34.5      0      0   330911   7.8292     0  ...           1   \n",
       "1  47.0      1      0   363272   7.0000     0  ...           0   \n",
       "2  62.0      0      0   240276   9.6875     0  ...           1   \n",
       "3  27.0      0      0   315154   8.6625     0  ...           1   \n",
       "4  22.0      1      1  3101298  12.2875     0  ...           0   \n",
       "\n",
       "   Embarked_encoded  Cabin_encoded  xgb_survived  lgb_survived  \\\n",
       "0                 1              0             0             0   \n",
       "1                 2              0             0             0   \n",
       "2                 1              0             0             0   \n",
       "3                 2              0             0             0   \n",
       "4                 2              0             0             1   \n",
       "\n",
       "   log_reg_survived  dt_survived  pooled_survived  any_survived  tfdf_survived  \n",
       "0                 0            0                0             0              0  \n",
       "1                 0            1                0             1              0  \n",
       "2                 0            0                0             0              0  \n",
       "3                 0            0                0             0              0  \n",
       "4                 1            0                0             1              0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Convert the pandas DataFrame to a TensorFlow dataset\n",
    "train_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(train_df[['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_encoded', 'Survived']], label=\"Survived\")\n",
    "test_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(test_df[['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_encoded']], label=None)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = tfdf.keras.RandomForestModel()\n",
    "model.fit(train_dataset, verbose=0)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "tfdf_predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to binary outcome\n",
    "tfdf_predictions = (tfdf_predictions >= 0.5).astype(int)\n",
    "# Add the predictions to the test dataframe\n",
    "test_df['tfdf_survived'] = tfdf_predictions\n",
    "\n",
    "# Display the first few rows of the test dataframe to verify the predictions\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['PassengerId', 'tfdf_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival/TFDFpredictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ydf in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ydf) (1.26.4)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ydf) (2.1.0)\n",
      "Requirement already satisfied: protobuf>=3.14 in /usr/local/lib/python3.10/dist-packages (from ydf) (4.25.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install YDF\n",
    "!pip install ydf -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 891 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_vocab_count = -1 for column Survived, the dictionary will not be pruned by size.\n",
      "\"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "Data spec:\n",
      "Number of records: 891\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 5 (83.3333%)\n",
      "\tCATEGORICAL: 1 (16.6667%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 5 (83.3333%)\n",
      "\t1: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602 dtype:DTYPE_INT64\n",
      "\t2: \"Age\" NUMERICAL mean:29.6991 min:0.42 max:80 sd:12.9947 dtype:DTYPE_FLOAT64\n",
      "\t3: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212 dtype:DTYPE_INT64\n",
      "\t4: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605 dtype:DTYPE_INT64\n",
      "\t5: \"Sex_encoded\" NUMERICAL mean:0.647587 min:0 max:1 sd:0.477722 dtype:DTYPE_INT64\n",
      "\n",
      "CATEGORICAL: 1 (16.6667%)\n",
      "\t0: \"Survived\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"0\" 549 (61.6162%) dtype:DTYPE_INT64\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"Survived\" was removed from the input feature set.\n",
      "Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "Training gradient boosted tree on 891 example(s) and 5 feature(s).\n",
      "818 examples used for training and 73 examples used for validation\n",
      "\tnum-trees:1 train-loss:1.241145 train-accuracy:0.612469 valid-loss:1.196174 valid-accuracy:0.657534\n",
      "\tnum-trees:2 train-loss:1.165032 train-accuracy:0.745721 valid-loss:1.125815 valid-accuracy:0.739726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.244178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.668338\n",
      "Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "Final model num-trees:50 valid-loss:0.668338 valid-accuracy:0.876712\n",
      "Engine \"GradientBoostedTreesQuickScorerExtended\" built\n"
     ]
    }
   ],
   "source": [
    "import ydf\n",
    "\n",
    "train_dataset = train_df[['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_encoded', 'Survived']]\n",
    "test_dataset = test_df[['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_encoded']]\n",
    "\n",
    "\n",
    "# Train a Gradient Boosted Trees model\n",
    "model = ydf.GradientBoostedTreesLearner(label=\"Survived\").train(train_dataset)\n",
    "\n",
    "# Look at a model (input features, training logs, structure, etc.)\n",
    "model.describe()\n",
    "\n",
    "# Evaluate a model (e.g. roc, accuracy, confusion matrix, confidence intervals)\n",
    "# model.evaluate(test_dataset)\n",
    "\n",
    "# Generate predictions\n",
    "ydf_prediction = model.predict(test_dataset)\n",
    "\n",
    "# Analyse a model (e.g. partial dependence plot, variable importance)\n",
    "# model.analyze(test_dataset)\n",
    "\n",
    "# Benchmark the inference speed of a model\n",
    "model.benchmark(test_dataset)\n",
    "\n",
    "# Convert predictions to binary outcome\n",
    "ydf_prediction = (ydf_prediction >= 0.5).astype(int)\n",
    "# Add the predictions to the test dataframe\n",
    "test_df['ydf_survived'] = ydf_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['PassengerId', 'ydf_survived']].to_csv('Binary Classification/Scikit-Learn/Titanic Survival/YDF_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Embarked_encoded</th>\n",
       "      <th>Cabin_encoded</th>\n",
       "      <th>dt_survived</th>\n",
       "      <th>cb_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Sex_encoded  \\\n",
       "0  34.5      0      0   330911   7.8292     0        Q            1   \n",
       "1  47.0      1      0   363272   7.0000     0        S            0   \n",
       "2  62.0      0      0   240276   9.6875     0        Q            1   \n",
       "3  27.0      0      0   315154   8.6625     0        S            1   \n",
       "4  22.0      1      1  3101298  12.2875     0        S            0   \n",
       "\n",
       "   Embarked_encoded  Cabin_encoded  dt_survived  cb_survived  \n",
       "0                 1              0            0            0  \n",
       "1                 2              0            0            0  \n",
       "2                 1              0            0            0  \n",
       "3                 2              0            0            0  \n",
       "4                 2              0            1            1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'rsm' : [0.6, 0.8, 1.0],\n",
    "    \n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "cb_clf = CatBoostClassifier(random_seed=42, verbose=0)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search_cb = RandomizedSearchCV(estimator=cb_clf, param_distributions=param_grid, n_iter=50, scoring='accuracy', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search_cb.fit(features_df, labels_df)\n",
    "\n",
    "# Get the best estimator\n",
    "best_cb_clf = random_search_cb.best_estimator_\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "cb_predictions = best_cb_clf.predict(test_features_df)\n",
    "\n",
    "# Add the predictions to the test dataframe\n",
    "test_df['cb_survived'] = cb_predictions\n",
    "\n",
    "# Display the first few rows of the test dataframe to verify the predictions\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['PassengerId', 'cb_survived']].to_csv('Data-Science/Binary Classification/Scikit-Learn/Titanic Survival/CB_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.09888171, 11.24888752,  5.4252049 ,  2.30161554, 56.92541033])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cb_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
